{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "from pymongo import MongoClient\n",
    "from pymongo.server_api import ServerApi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb+srv://3bmWDannaH:vUgxi8@cluster0.x4iqn2s.mongodb.net/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://quotes.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функція для збирання інформації про авторів зі всіх сторінок\n",
    "def scrape_authors(url):\n",
    "    authors_data = []\n",
    "\n",
    "    page_num = 1\n",
    "    while True:\n",
    "        response = requests.get(f\"{url}/page/{page_num}\")\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        authors = soup.find_all('small', class_='author')\n",
    "        if not authors:\n",
    "            break\n",
    "        for auth in authors:\n",
    "            author_name = auth.text\n",
    "            relative_url = 'author/' + re.sub(r'-+', '-', author_name.replace(' ', '-').replace('.', '-')).replace('é', 'e')\n",
    "            full_url = 'https://quotes.toscrape.com/' + relative_url\n",
    "            author_data = scrape_authors_info(full_url)\n",
    "            if author_data not in authors_data:\n",
    "                authors_data.append(author_data)\n",
    "        page_num += 1\n",
    "\n",
    "    return authors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функція для збирання внутрішньої інформації про автора\n",
    "def scrape_authors_info(full_url):\n",
    "    response = requests.get(full_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    fullname = soup.find('h3', class_='author-title').text.strip()\n",
    "    born_date = soup.find('span', class_='author-born-date').get_text(strip=True)\n",
    "    born_location = soup.find('span', class_='author-born-location').get_text(strip=True)\n",
    "    description = soup.find('div', class_='author-description').get_text(strip=True)\n",
    "\n",
    "    author_data = {\n",
    "        \"fullname\": fullname,\n",
    "        \"born_date\": born_date,\n",
    "        \"born_location\": born_location,\n",
    "        \"description\": description\n",
    "    }\n",
    "\n",
    "    return author_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функція для збирання цитат зі всіх сторінок\n",
    "def scrape_quotes(url):\n",
    "    quotes_data = []\n",
    "\n",
    "    page_num = 1\n",
    "    while True:\n",
    "        response = requests.get(f'{url}/page/{page_num}')\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        quotes = soup.find_all('div', class_='quote')\n",
    "        if not quotes:\n",
    "            break\n",
    "        for quote in quotes:\n",
    "            text = quote.find('span', class_='text').text\n",
    "            author = quote.find('small', class_='author').text\n",
    "            tags = [tag.text for tag in quote.find_all('a', class_='tag')]\n",
    "            quotes_data.append({\n",
    "                \"author\": author,\n",
    "                \"quote\": text,\n",
    "                \"tags\": tags\n",
    "            })\n",
    "        page_num += 1\n",
    "\n",
    "    return quotes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://quotes.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('quotes.json', 'w', encoding='UTF-8') as quotes_file:\n",
    "    json.dump(quotes, quotes_file, indent=4)\n",
    "\n",
    "with open('authors.json', 'w', encoding='UTF-8') as authors_file:\n",
    "    # Видаляємо поле \"_id\" з кожного документа у списку authors_data\n",
    "    for author in authors_data:\n",
    "        author.pop('_id', None)\n",
    "    json.dump(authors_data, authors_file, indent=4)\n",
    "\n",
    "with open('quotes.json', 'r', encoding='UTF-8') as quotes_file:\n",
    "    quotes_data = json.load(quotes_file)\n",
    "    result_quotes = db.quotes.insert_many(quotes_data)\n",
    "\n",
    "with open('authors.json', 'r', encoding='UTF-8') as authors_file:\n",
    "    authors_data = json.load(authors_file)\n",
    "    for author in authors_data:\n",
    "        author.pop('_id', None)  # Видаляємо поле _id\n",
    "    result_authors = db.authors.insert_many(authors_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дані було успішно записано у файли quotes.json та authors.json\n"
     ]
    }
   ],
   "source": [
    "print(\"Дані було успішно записано у файли quotes.json та authors.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
